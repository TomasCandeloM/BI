{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja 3\n",
    "## Carlos Farouk Abdala\n",
    "## Tomas Candelo \n",
    "## Gabriel Jimenez "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CLILI\\AppData\\Local\\Temp\\ipykernel_30380\\2080034654.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "### Exercise 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalues of D_covariance \n",
      " [ 0.03990796 14.84898093] \n",
      "\n",
      "eigenvectors of D_covariance \n",
      " [[-0.84710349 -0.53142795]\n",
      " [ 0.53142795 -0.84710349]] \n",
      "\n",
      "eigenvalues of trans_D_covariance \n",
      " [ 0.15963186 59.3959237 ] \n",
      "\n",
      "eigenvectors of trans_D_covariance \n",
      " [[-0.84710349 -0.53142795]\n",
      " [ 0.53142795 -0.84710349]]\n"
     ]
    }
   ],
   "source": [
    "# matrix without function\n",
    "\n",
    "D = np.array([[10, 12], [7, 8], [5, 4]])\n",
    "D_covariance = np.cov(D, rowvar=False, bias=True)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(D_covariance)\n",
    "print(\"eigenvalues of D_covariance \\n\", eigenvalues, \"\\n\")\n",
    "print(\"eigenvectors of D_covariance \\n\", eigenvectors, \"\\n\")\n",
    "\n",
    "# matrix with function\n",
    "def transformation (x):\n",
    "    return 2*x + 5\n",
    "function = np.vectorize(transformation)\n",
    "trans_D = function(D)    \n",
    "trans_D_covariance = np.cov(trans_D, rowvar=False, bias=True)\n",
    "eigenvalues_trans, eigenvectors_trnas = np.linalg.eig(trans_D_covariance)\n",
    "print(\"eigenvalues of trans_D_covariance \\n\", eigenvalues_trans, \"\\n\")\n",
    "print(\"eigenvectors of trans_D_covariance \\n\", eigenvectors_trnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso buscamos demostrar que los componentes principales, vectores propios de la matriz de correlación, es igual en la matriz original y la matriz transformada por una función afin, primero decleremos los siguientes valores:\n",
    "D ------> La matriz sin transformar  \n",
    "DTrans -------> La matriz tranformada por una transformación  \n",
    "covarianza --------> matriz de covarianza de D  \n",
    "covarianza_transformada --------> matriz de covarianza de DT  \n",
    "vector propio ------> vectores propios de la matriz de correlación  \n",
    "\n",
    "Una vez definido esto es necesario centrar los datos de la matriz para obtener la covarianza de esta la cual esta definida por la siguiente ecuación\n",
    "$$ ecuación 1: covarianzaTranformada = \\frac{1}{n} \\sum_{i=1}^{n} (D_centradoT * D_centrado) $$\n",
    "Donde D_centradoT son los datos centralizados transpuestos y D_centrado son los datos centrados normales y se expresan como \n",
    "$$ euación 2: D_centrado = D - media $$\n",
    "\n",
    "Esta ecuación de la covarianza la vamos a asemejar como la de correlación ya que estas dos matrices son semejantes en este caso  \n",
    "\n",
    "De la hoja anterior podemos de igual manera decir que la media transformada esta determinada por la siguiente ecuación\n",
    "$$ ecuación 3: media-tranfrormada = a*media + b $$\n",
    "\n",
    "Entonces si aplicamos la matriz transformada a la ecuación 1 y los valores centrados los cambiamos por la ecuación 2 tendriamos que\n",
    "$$  Correlación-Transformada = \\frac{1}{n} * (DTtrans - mediaTransformadaT)T * (DT - mediaTransformadaT) $$\n",
    "\n",
    "Ahora si cambiamos los valores de la ecuacíon por la formula que equivale su tranformación seria\n",
    "\n",
    "$$  \\frac{1}{n} * (a*D + b - a*media + b)T * (a*D + b - a*media + b) $$\n",
    "\n",
    "simplificamos y obtenemos \n",
    "\n",
    "$$  \\frac{1}{n} * DT*AT*AD - \\frac{1}{n} * DT*AT*A*media - \\frac{1}{n} mediaT * AT * AD - \\frac{1}{n} mediaT*AT * A*media $$ \n",
    "\n",
    "Dado que A es una matriz de valores escalares A*AT tambien es una matriz escalar y ya que la definición dada en la hoja nos dice que la matriz de covarianza y correlación son iguales porque sus valores son igual a 1 la expersión anterior puede ser simplificada a: \n",
    "\n",
    "$$  \\frac{1}{n} * DT*D - \\frac{1}{n} * DT*media - \\frac{1}{n} mediaT*D - \\frac{1}{n} mediaT*media $$\n",
    "\n",
    "simplificando nuevamente obtenemos que \n",
    "\n",
    "$$  \\frac{1}{n} * DT*D - mediaT * media$$\n",
    "\n",
    "lo cual es semejante a decir que la correlación tranformada es igual a 1/n * Σ siendo sigma la matriz de covarianza original  \n",
    "\n",
    "Si todo esto lo aplicamos a la formula Σ*v = α*v donde v son nuestros vectores propios y α es el valor propio, podemos concluir que la matriz de correlación, despues de transformarla, esta dada como una versión escalar de la matriz de covarianza original y las componentes principlaes (nuestros valores o vectores propios) estan relacionadas unicamente con la matriz de covarianza o de correlación, ya que estas son iguales entre si gracias a que sus varianzas equivalen a 1, por lo que estos componentes principales tampoco cambiaran, además cabe resaltar que α no cambia ni en la ecuación tranformada o sin tranformar, en otras palabras v'es el vector propio de la correlación de la matriz transformada que tiene como valor propio a α el cual es el mismo que tiene el vector propio v de la correlación de la matriz original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "### Exercise 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.49723766 -0.1938108  -0.35030652  0.75479112]\n",
      " [-0.05748209 -0.69798827 -0.02652233 -0.08789238]\n",
      " [ 0.7852392  -0.18120468  0.20005293  0.55594024]\n",
      " [-0.2436471   0.48392027  0.57050068  0.33248551]\n",
      " [ 0.27108302  0.4563286  -0.71490539  0.05430585]]\n",
      "Resized Matrix: \n",
      " [[-2.07059248  6.53267977 -2.01248537  6.35808852]\n",
      " [-5.39803817 -4.84754604 -0.48330798  8.60724781]\n",
      " [ 0.70383031 -1.07539475 -2.79670381  5.51650909]\n",
      " [ 3.83600714  1.27511552 -4.76225431  9.67644699]\n",
      " [-4.2217642   2.6606485   2.07104514  6.40025317]\n",
      " [ 2.26239488  0.75573563  1.97241032  4.03002206]\n",
      " [ 3.18388159  0.32867746  1.54817188  8.05010852]\n",
      " [ 7.07565103 -2.54169651  0.49322288  5.69078781]\n",
      " [-0.89351006 -1.04329265 -5.25276934  3.23802319]\n",
      " [-2.94545551 -2.92592139 -1.03780115  5.69698744]]\n"
     ]
    }
   ],
   "source": [
    "def PCA (D,red):\n",
    "    u= np.array([])\n",
    "    mean_of_D= np.mean(D)\n",
    "    center_D= D-mean_of_D\n",
    "    cov_D = np.cov(center_D, rowvar=False, bias=True)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_D)\n",
    "    #print(\"\\nEigenvalues: \\n\",eigenvalues,\"\\n\\nEigenvectors: \\n\", eigenvectors, \"\\n\")\n",
    " \n",
    "    order_indices = np.argsort(eigenvalues)[::-1].tolist()\n",
    "    sorted_eigenvalues = eigenvalues[order_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, order_indices]\n",
    " \n",
    "    if(0<=red and red<1):\n",
    "        red_acum_variance=(sum(eigenvalues)*red)\n",
    "        acum_variance=0\n",
    "        r=0\n",
    "        for index in range(len(sorted_eigenvalues)):\n",
    "            if (sorted_eigenvalues[index]+acum_variance)<= red_acum_variance:\n",
    "                r=r+1\n",
    "                acum_variance= acum_variance+ sorted_eigenvalues[index]\n",
    "            else:\n",
    "                break\n",
    "        if r!=0:\n",
    "            u= sorted_eigenvectors[:,:r]\n",
    "            D_resized = np.dot(D, u)\n",
    "        else:\n",
    "            return (\"El valor de alpha solicitado es inválido para la matriz\",0)\n",
    "       \n",
    "    if(red>=1 and int == type(red)):\n",
    "        u= sorted_eigenvectors[:,:red]\n",
    "        print(u)\n",
    "        D_resized = np.dot(D, u)\n",
    "    mean_D_resized = np.mean(D_resized)\n",
    "    squared_D = np.sum((D_resized - mean_D_resized)**2)\n",
    "    variance = squared_D / D_resized.size\n",
    "    return (D_resized,variance)\n",
    " \n",
    " \n",
    "xd=np.array([[4, 1, 0, 9, 8],\n",
    " [9, 9, 1, 6, 1],\n",
    " [4, 5, 3, 3, 5],\n",
    " [6, 2, 7, 3, 8],\n",
    " [5, 1, 0, 8, 1],\n",
    " [0, 4, 4, 6, 3],\n",
    " [3, 3, 7, 6, 3],\n",
    " [0, 6, 9, 3, 4],\n",
    " [4, 5, 0, 1, 6],\n",
    " [6, 5, 1, 3, 1]])\n",
    " \n",
    "result_resized_matrix,x=PCA1(xd,4)\n",
    " \n",
    " \n",
    "#np.random.randint(0, 10,(10,5))\n",
    " \n",
    "print(\"Resized Matrix: \\n\",result_resized_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames implementation\n",
    "iris_frame_dowloaded = pd.read_csv(\"iris.csv\")\n",
    "filtered_iris_frame = iris_frame_dowloaded.loc[:, iris_frame_dowloaded.columns != \"species\"]\n",
    "fabert_frame_dowloaded = pd.read_csv(\"fabert.csv\")\n",
    "filtered_fabert_frame = fabert_frame_dowloaded.loc[:, fabert_frame_dowloaded.columns != \"class\"]\n",
    "Amazon_frame_dowloaded = pd.read_csv(\"Amazon.csv\")\n",
    "filtered_Amazon_frame = Amazon_frame_dowloaded.loc[:, Amazon_frame_dowloaded.columns != \"Class\"]\n",
    "baseball_numeric_frame_dowloaded = pd.read_csv(\"baseball_numeric.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(A):\n",
    "    n = len(A) \n",
    "    m = len(A[0]) \n",
    "\n",
    "    mean = [sum(col) / n for col in zip(*A)]\n",
    "\n",
    "    central_A = [[A[i][j] - mean[j] for j in range(m)] for i in range(n)]\n",
    "    central_A2=np.array(central_A)\n",
    "\n",
    "    cov = np.dot(central_A2.T, central_A2) / n\n",
    "\n",
    "    std_dev = np.sqrt(np.diag(cov))\n",
    "    corr = [[cov[j][k] / (std_dev[j] * std_dev[k]) for k in range(m)] for j in range(m)]\n",
    "    \n",
    "    return mean, cov, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_38352\\3964515318.py:14: DeprecationWarning: bias and ddof have no effect and are deprecated\n",
      "  corr2 = np.corrcoef(dataset, rowvar=False, bias=True)\n",
      "C:\\Users\\tomas\\AppData\\Local\\Temp\\ipykernel_38352\\3409762023.py:13: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  corr = [[cov[j][k] / (std_dev[j] * std_dev[k]) for k in range(m)] for j in range(m)]\n",
      "C:\\Users\\tomas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\tomas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dataset  time with getStats  time with corcoef\n",
      "0              iris            0.040632           0.022855\n",
      "1            fabert            3.910621           0.158933\n",
      "2            amazon          228.678112           4.691061\n",
      "3  baseball numeric            0.100481           0.112915\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "data = {\"dataset\": [\"iris\", \"fabert\", \"amazon\", \"baseball numeric\"], \"time with getStats\": [], \"time with corcoef\": []}\n",
    "\n",
    "\n",
    "datasets = [filtered_iris_frame, filtered_fabert_frame, filtered_Amazon_frame, baseball_numeric_frame_dowloaded]\n",
    "for dataset in datasets:\n",
    "    start1 = time.time()\n",
    "    data_np = dataset.to_numpy()\n",
    "    getStats(data_np)\n",
    "    end1 = time.time()\n",
    "    excecuting_time_with_getStats = end1 - start1\n",
    "    start2 = time.time()\n",
    "    corr2 = np.corrcoef(dataset, rowvar=False, bias=True)\n",
    "    end2 = time.time()\n",
    "    excecuting_time_with_corcoef = end2 - start2\n",
    "    data[\"time with getStats\"].append(excecuting_time_with_getStats)\n",
    "    data[\"time with corcoef\"].append(excecuting_time_with_corcoef)\n",
    "\n",
    "data_frame = pd.DataFrame(data)\n",
    "print(data_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dataset  requiere dimensions  absolut variance  relative variance\n",
      "0              iris                    1          0.000000       0.000000e+00\n",
      "1            fabert                  515          0.004901       2.814406e-07\n",
      "2            amazon                10000          0.000000       0.000000e+00\n",
      "3  baseball numeric                    1      11819.241260       6.787627e-01\n"
     ]
    }
   ],
   "source": [
    "red = 0.9\n",
    "data = {\"dataset\": [\"iris\", \"fabert\", \"amazon\", \"baseball numeric\"], \"requiere dimensions\": [], \"absolut variance\": [], \"relative variance\": []}\n",
    "\n",
    "datasets = [filtered_iris_frame, filtered_fabert_frame, filtered_Amazon_frame, baseball_numeric_frame_dowloaded]\n",
    "for dataset in datasets:\n",
    "    resized_matrix, variance = PCA(dataset, red)\n",
    "    data[\"requiere dimensions\"].append(len(resized_matrix[0]))\n",
    "    data[\"absolut variance\"].append(variance)\n",
    "    data[\"relative variance\"].append(variance/sum(np.diag(np.cov(data_np.T))))\n",
    "  \n",
    "data_frame = pd.DataFrame(data)\n",
    "print(data_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
