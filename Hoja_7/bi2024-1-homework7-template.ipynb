{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templateobs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "## Exercise 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def testMetric(metric, D, X, Y, ex):\n",
    "    exString = str(ex)\n",
    "    dotIndex = exString.find(\".\")\n",
    "    floatPos = len(exString) - dotIndex - 1 if dotIndex >= 0 else 0\n",
    "    actOrig = getRuleMetric(D, X, Y, metric)\n",
    "    try:\n",
    "        act = np.round(actOrig, floatPos)\n",
    "    except:\n",
    "        print(\"PROBLEM WITH \" + str(actOrig))\n",
    "    print ((\"OK    \" if act == ex else \"FAIL  \") + metric + \"(\" + \"\".join([str(x) for x in X]) + \" -> \" + \"\".join([str(x) for x in Y]) + \")\" + ((\"Expected: \" + str(ex) + \" but was \" + str(act))  if act != ex else \"\"))\n",
    "\n",
    "def testMetrics():\n",
    "    D = read_database(\"exampleset_numeric.dat\")\n",
    "    testMetric(\"conf\", D, [1], [5], 1)\n",
    "    testMetric(\"conf\", D, [5], [1], 0.8)\n",
    "    testMetric(\"conf\", D, [2], [5], 0.83)\n",
    "    testMetric(\"conf\", D, [5], [2], 1)\n",
    "    testMetric(\"conf\", D, [5], [2, 3], 0.6)\n",
    "    testMetric(\"conf\", D, [2, 3], [5], 0.75)\n",
    "    testMetric(\"lift\", D, [1], [2], 1)\n",
    "    testMetric(\"lift\", D, [1], [3], 0.75)\n",
    "    testMetric(\"lift\", D, [1], [5], 1.2)\n",
    "    testMetric(\"leverage\", D, [1], [5], 0.11)\n",
    "    testMetric(\"lift\", D, [1, 3, 4], [5], 1.2)\n",
    "    testMetric(\"leverage\", D, [1, 3, 4], [5], 0.03)\n",
    "    testMetric(\"jaccard\", D, [1], [5], 0.8)\n",
    "    testMetric(\"jaccard\", D, [1], [2], 0.67)\n",
    "    testMetric(\"jaccard\", D, [1], [3], 0.33)\n",
    "    testMetric(\"conviction\", D, [1], [4,5], 2)\n",
    "    testMetric(\"conviction\", D, [5], [3], 0.83)\n",
    "    testMetric(\"conviction\", D, [3], [5], 0.67)\n",
    "    testMetric(\"conviction\", D, [4, 5], [1], np.inf)\n",
    "    testMetric(\"oddsratio\", D, [1], [3], 0)\n",
    "    testMetric(\"oddsratio\", D, [1], [4], 3)\n",
    "    testMetric(\"imp\", D, [2, 5], [3], -0.07)\n",
    "    testMetric(\"imp\", D, [2, 3], [5], -0.08)\n",
    "    testMetric(\"imp\", D, [3, 5], [2], 0.0)\n",
    "    testMetric(\"imp\", D, [4, 5], [1], 0.2)\n",
    "\n",
    "testMetrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_equalness(exp, act):\n",
    "    length_exp = len(exp)\n",
    "    length_act = len(act)\n",
    "    print(\"Length of collection: \" + str(\"OK\" if length_exp == length_act else \"FAILED, expected length \" + str(length_exp) + \" but saw \" + str(length_act)))\n",
    "    obsolete = [f for f in act if not f in exp]\n",
    "    missing = [f for f in exp if not f in act]\n",
    "    if obsolete:\n",
    "        print(\"Found unexpected entries: \" + str(obsolete))\n",
    "        return False\n",
    "    if missing:\n",
    "        print(\"Missing entries: \" + str(missing))\n",
    "        return False\n",
    "    return True\n",
    "        \n",
    "def testFilter():\n",
    "    D = read_database(\"exampleset_numeric.dat\")\n",
    "    R = getStrongRules(D, 3, 1.0)\n",
    "    RF_act = filterProductiveRules(D, R)\n",
    "    \n",
    "    for r in RF_act:\n",
    "        if type(r) != tuple:\n",
    "            print(\"Element in reduced rule set is not a tuple: \" + str(r))\n",
    "            return\n",
    "        if len(r) != 4:\n",
    "            print(\"Length of tuple is not 4: \" + str(r))\n",
    "            return\n",
    "    \n",
    "    RF_exp = [([4, 5], [1, 2], 3, 1.0), ([1], [2, 5], 4, 1.0), ([4, 5], [1], 3, 1.0), ([1], [5], 4, 1.0)]\n",
    "    equal = test_set_equalness(RF_exp, RF_act)\n",
    "    print(\"Filter test: \" + (\"OK\" if equal else \"FAILED\"))\n",
    "    \n",
    "testFilter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3\n",
    "no tests for this exercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
